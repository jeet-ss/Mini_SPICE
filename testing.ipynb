{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 20:25:22.265305: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-25 20:25:22.306813: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-25 20:25:22.833794: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from utils.model import Spice_model\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "from data_files.dataloader import MedleyDBLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.model import Spice_model\n",
    "from utils.training_script import Trainer\n",
    "from optims.loss import Huber_loss, Recons_loss, Conf_loss\n",
    "from data_files.dataset import CQT_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fadd4caca10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "torch.manual_seed(191009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell2(torch.nn.Module):\n",
    "    def __init__(self, dg):\n",
    "        super(MyCell2, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forwardMyDecisionGate(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.3179, -0.0809, -0.6178,  0.3956],\n",
      "        [ 0.6665,  0.1408,  0.4307,  0.7632],\n",
      "        [ 0.5047, -0.2405, -0.1733,  0.6841]], grad_fn=<TanhBackward0>), tensor([[ 0.3179, -0.0809, -0.6178,  0.3956],\n",
      "        [ 0.6665,  0.1408,  0.4307,  0.7632],\n",
      "        [ 0.5047, -0.2405, -0.1733,  0.6841]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "my_cell = MyCell()\n",
    "x = torch.rand(3, 4)\n",
    "h = torch.rand(3, 4)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracd MyCell(\n",
      "  original_name=MyCell\n",
      "  (linear): Linear(original_name=Linear)\n",
      ") end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0416,  0.7165,  0.5299, -0.0434],\n",
       "         [ 0.2687,  0.1412,  0.6382,  0.1054],\n",
       "         [ 0.3480,  0.5014,  0.6016, -0.3498]], grad_fn=<TanhBackward0>),\n",
       " tensor([[-0.0416,  0.7165,  0.5299, -0.0434],\n",
       "         [ 0.2687,  0.1412,  0.6382,  0.1054],\n",
       "         [ 0.3480,  0.5014,  0.6016, -0.3498]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cell = MyCell()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(\"tracd\",traced_cell,\"end\")\n",
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\n",
      "  return (_0, _0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(traced_cell.graph)\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  return torch.neg(argument_1)\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  _1 = torch.tanh(_0)\n",
      "  return (_1, _1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_394348/3990843855.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum() > 0:\n"
     ]
    }
   ],
   "source": [
    "my_cell = MyCell2(MyDecisionGate())\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "\n",
    "print(traced_cell.dg.code)\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.neg(x)\n",
      "  return _0\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n",
      "(tensor([[0.0638, 0.9258, 0.5977, 0.2638],\n",
      "        [0.2533, 0.6691, 0.6879, 0.5501],\n",
      "        [0.5337, 0.8923, 0.7698, 0.2902]], grad_fn=<TanhBackward0>), tensor([[0.0638, 0.9258, 0.5977, 0.2638],\n",
      "        [0.2533, 0.6691, 0.6879, 0.5501],\n",
      "        [0.5337, 0.8923, 0.7698, 0.2902]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "scripted_gate = torch.jit.script(MyDecisionGate())\n",
    "\n",
    "my_cell = MyCell2(scripted_gate)\n",
    "scripted_cell = torch.jit.script(my_cell)\n",
    "\n",
    "print(scripted_gate.code)\n",
    "print(scripted_cell.code)\n",
    "print(scripted_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Type '<class '__main__.MyRNNLoop'>' cannot be compiled since it inherits from nn.Module, pass an instance instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m@torch\u001b[39;49m\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mscript\n\u001b[0;32m----> 2\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mMyRNNLoop\u001b[39;49;00m(torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[39mdef\u001b[39;49;00m \u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m):\n\u001b[1;32m      4\u001b[0m         \u001b[39msuper\u001b[39;49m(MyRNNLoop, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m()\n",
      "File \u001b[0;32m~/anaconda3/envs/mpa/lib/python3.10/site-packages/torch/jit/_script.py:1298\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[39m# If this type is a `nn.Module` subclass, they probably meant to pass\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[39m# an instance instead of a Module\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(obj, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m-> 1298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1299\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mType \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m cannot be compiled since it inherits\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m from nn.Module,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1301\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m pass an instance instead\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj)\n\u001b[1;32m   1302\u001b[0m     )\n\u001b[1;32m   1304\u001b[0m \u001b[39m# Enums are automatically usable in TorchScript, explicitly scripting\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[39m# is not necessary, but not harmful either.\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(obj, enum\u001b[39m.\u001b[39mEnum):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Type '<class '__main__.MyRNNLoop'>' cannot be compiled since it inherits from nn.Module, pass an instance instead"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyRNNLoop(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRNNLoop, self).__init__()\n",
    "        self.cell = torch.jit.trace(MyCell2(scripted_gate), (x, h))\n",
    "    @torch.jit.script\n",
    "    def forward(self, xs):\n",
    "        h, y = torch.zeros(3, 4), torch.zeros(3, 4)\n",
    "        for i in range(xs.size(0)):\n",
    "            y, h = self.cell(xs[i], h)\n",
    "        return y, h\n",
    "\n",
    "rnn_loop = MyRNNLoop()\n",
    "print(rnn_loop.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16000\n",
    "med = MedleyDBLoader(fs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9528461205301544e+16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = 1110.0644999999954 \n",
    "f2 = -5.684341886080802e-14\n",
    "dive = f1/f2\n",
    "dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23855/3868652844.py:1: RuntimeWarning: invalid value encountered in log2\n",
      "  np.log2(dive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(dive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.read_pickle('./CQT_data/MIR1k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnp = np.load('./CQT_data/MedleyDB.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnp = torch.toTe(nnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3530, 191)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (2824, 191)\n",
      "train_batch NUmber:  45\n",
      "diff batch shape: torch.Size([64])\n",
      "slice1 batch shape: torch.Size([64, 128])\n",
      "slice2 batch shape: torch.Size([64])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([8])\n",
      "torch.Size([8, 1]) torch.Size([8, 1]) torch.Size([8, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "#data_pd = pd.DataFrame(data=nnp) \n",
    "train, val = train_test_split(data_pd, train_size=0.8, test_size=0.2, random_state=1)\n",
    "print(\"train shape: \", train.shape)\n",
    "train_batches = DataLoader(CQT_Dataset(data=train, mode='train'), batch_size=64, shuffle=True)\n",
    "print(\"train_batch NUmber: \", len(train_batches))\n",
    "diff, slice1, slice2, f0 = next(iter(train_batches))\n",
    "print(f\"diff batch shape: {diff.size()}\")\n",
    "print(f\"slice1 batch shape: {slice1.size()}\")\n",
    "print(f\"slice2 batch shape: {f0.size()}\")\n",
    "\n",
    "spice = Spice_model()\n",
    "\n",
    "\n",
    "for b in train_batches:\n",
    "    print(\"batch shape:\", b[0].shape)\n",
    "    pitch_diff, x_1, x_2, f0 = b\n",
    "    x_1 = x_1.type(torch.FloatTensor)\n",
    "    #print(x_1.shape, x_1.type())\n",
    "    a, x, y = spice(x_1)\n",
    "    print(a.size(), x.size(), y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=torch.arange(0, 25, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = xx.reshape((5,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./CQT_data/MIR1k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,25,1).reshape(5,5)[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0,15,1).reshape(5,3)\n",
    "a = np.hstack((a, np.array([0.25,0.7,0,0.5,0]).reshape(-1,1)))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows of cqt where label (last) column is zero\n",
    "df.drop(df.loc[df.iloc[:, -1]==0].index, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder forward torch.FloatTensor\n",
      "Encoder forward torch.FloatTensor\n",
      "Encoder forward torch.FloatTensor\n",
      "Encoder forward torch.FloatTensor\n",
      "Encoder forward torch.FloatTensor\n",
      "Encoder forward torch.FloatTensor\n",
      "no unpooling True True\n",
      "no unpooling False True\n",
      "no unpooling False True\n",
      "no unpooling False True\n",
      "no unpooling False True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Spice_model                              [10, 1]                   --\n",
       "├─Spice_Encoder: 1-1                     [10, 1]                   --\n",
       "│    └─Conv_block: 2-1                   [10, 64, 64]              --\n",
       "│    │    └─Conv1d: 3-1                  [10, 64, 128]             256\n",
       "│    │    └─BatchNorm1d: 3-2             [10, 64, 128]             128\n",
       "│    │    └─ReLU: 3-3                    [10, 64, 128]             --\n",
       "│    │    └─MaxPool1d: 3-4               [10, 64, 64]              --\n",
       "│    └─Conv_block: 2-2                   [10, 128, 32]             --\n",
       "│    │    └─Conv1d: 3-5                  [10, 128, 64]             24,704\n",
       "│    │    └─BatchNorm1d: 3-6             [10, 128, 64]             256\n",
       "│    │    └─ReLU: 3-7                    [10, 128, 64]             --\n",
       "│    │    └─MaxPool1d: 3-8               [10, 128, 32]             --\n",
       "│    └─Conv_block: 2-3                   [10, 256, 16]             --\n",
       "│    │    └─Conv1d: 3-9                  [10, 256, 32]             98,560\n",
       "│    │    └─BatchNorm1d: 3-10            [10, 256, 32]             512\n",
       "│    │    └─ReLU: 3-11                   [10, 256, 32]             --\n",
       "│    │    └─MaxPool1d: 3-12              [10, 256, 16]             --\n",
       "│    └─Conv_block: 2-4                   [10, 512, 8]              --\n",
       "│    │    └─Conv1d: 3-13                 [10, 512, 16]             393,728\n",
       "│    │    └─BatchNorm1d: 3-14            [10, 512, 16]             1,024\n",
       "│    │    └─ReLU: 3-15                   [10, 512, 16]             --\n",
       "│    │    └─MaxPool1d: 3-16              [10, 512, 8]              --\n",
       "│    └─Conv_block: 2-5                   [10, 512, 4]              --\n",
       "│    │    └─Conv1d: 3-17                 [10, 512, 8]              786,944\n",
       "│    │    └─BatchNorm1d: 3-18            [10, 512, 8]              1,024\n",
       "│    │    └─ReLU: 3-19                   [10, 512, 8]              --\n",
       "│    │    └─MaxPool1d: 3-20              [10, 512, 4]              --\n",
       "│    └─Conv_block: 2-6                   [10, 512, 2]              --\n",
       "│    │    └─Conv1d: 3-21                 [10, 512, 4]              786,944\n",
       "│    │    └─BatchNorm1d: 3-22            [10, 512, 4]              1,024\n",
       "│    │    └─ReLU: 3-23                   [10, 512, 4]              --\n",
       "│    │    └─MaxPool1d: 3-24              [10, 512, 2]              --\n",
       "│    └─Linear: 2-7                       [10, 48]                  49,200\n",
       "│    └─Linear: 2-8                       [10, 1]                   49\n",
       "│    └─Linear: 2-9                       [10, 1]                   1,025\n",
       "├─Spice_Decoder: 1-2                     [10, 32, 4]               --\n",
       "│    └─Linear: 2-10                      [10, 1, 48]               96\n",
       "│    └─Linear: 2-11                      [10, 1, 1024]             50,176\n",
       "│    └─Deconv_block: 2-12                [10, 256, 4]              512\n",
       "│    │    └─MaxUnpool1d: 3-25            [10, 512, 4]              --\n",
       "│    │    └─ConvTranspose1d: 3-26        [10, 256, 4]              393,472\n",
       "│    │    └─ReLU: 3-27                   [10, 256, 4]              --\n",
       "│    └─Deconv_block: 2-13                [10, 256, 4]              512\n",
       "│    │    └─ConvTranspose1d: 3-28        [10, 256, 4]              196,864\n",
       "│    │    └─ReLU: 3-29                   [10, 256, 4]              --\n",
       "│    └─Deconv_block: 2-14                [10, 256, 4]              512\n",
       "│    │    └─ConvTranspose1d: 3-30        [10, 256, 4]              196,864\n",
       "│    │    └─ReLU: 3-31                   [10, 256, 4]              --\n",
       "│    └─Deconv_block: 2-15                [10, 128, 4]              256\n",
       "│    │    └─ConvTranspose1d: 3-32        [10, 128, 4]              98,432\n",
       "│    │    └─ReLU: 3-33                   [10, 128, 4]              --\n",
       "│    └─Deconv_block: 2-16                [10, 64, 4]               128\n",
       "│    │    └─ConvTranspose1d: 3-34        [10, 64, 4]               24,640\n",
       "│    │    └─ReLU: 3-35                   [10, 64, 4]               --\n",
       "│    └─Deconv_block: 2-17                [10, 32, 4]               64\n",
       "│    │    └─ConvTranspose1d: 3-36        [10, 32, 4]               6,176\n",
       "│    │    └─ReLU: 3-37                   [10, 32, 4]               --\n",
       "==========================================================================================\n",
       "Total params: 3,114,082\n",
       "Trainable params: 3,114,082\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 242.81\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 6.63\n",
       "Params size (MB): 12.45\n",
       "Estimated Total Size (MB): 19.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Spice_model()\n",
    "summary(s, input_size=[10, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n"
     ]
    }
   ],
   "source": [
    "for n, param in s.named_parameters():\n",
    "    print(type(param), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fed21d7f443e9082cfc6ba2fbe018596127843c8658e141820a67f60820f8cf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.11 ('mpa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
