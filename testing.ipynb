{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from utils.model import Spice_model\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Spice_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in decoder True torch.Size([10, 512, 2]) torch.Size([10, 512, 2])\n",
      "befoce 2deconv True 6\n",
      "2nd deconv torch.Size([10, 256, 4]) torch.Size([10, 256, 4])\n",
      "in decoder True torch.Size([10, 256, 4]) torch.Size([10, 256, 4])\n",
      "no unpooling False True\n",
      "no unpooling False True\n",
      "no unpooling False True\n",
      "no unpooling False True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Spice_model                              [10, 1]                   --\n",
       "├─Spice_Encoder: 1-1                     [10, 1]                   --\n",
       "│    └─Conv_block: 2-1                   [10, 64, 64]              --\n",
       "│    │    └─Conv1d: 3-1                  [10, 64, 128]             256\n",
       "│    │    └─BatchNorm1d: 3-2             [10, 64, 128]             128\n",
       "│    │    └─ReLU: 3-3                    [10, 64, 128]             --\n",
       "│    │    └─MaxPool1d: 3-4               [10, 64, 64]              --\n",
       "│    └─Conv_block: 2-2                   [10, 128, 32]             --\n",
       "│    │    └─Conv1d: 3-5                  [10, 128, 64]             24,704\n",
       "│    │    └─BatchNorm1d: 3-6             [10, 128, 64]             256\n",
       "│    │    └─ReLU: 3-7                    [10, 128, 64]             --\n",
       "│    │    └─MaxPool1d: 3-8               [10, 128, 32]             --\n",
       "│    └─Conv_block: 2-3                   [10, 256, 16]             --\n",
       "│    │    └─Conv1d: 3-9                  [10, 256, 32]             98,560\n",
       "│    │    └─BatchNorm1d: 3-10            [10, 256, 32]             512\n",
       "│    │    └─ReLU: 3-11                   [10, 256, 32]             --\n",
       "│    │    └─MaxPool1d: 3-12              [10, 256, 16]             --\n",
       "│    └─Conv_block: 2-4                   [10, 512, 8]              --\n",
       "│    │    └─Conv1d: 3-13                 [10, 512, 16]             393,728\n",
       "│    │    └─BatchNorm1d: 3-14            [10, 512, 16]             1,024\n",
       "│    │    └─ReLU: 3-15                   [10, 512, 16]             --\n",
       "│    │    └─MaxPool1d: 3-16              [10, 512, 8]              --\n",
       "│    └─Conv_block: 2-5                   [10, 512, 4]              --\n",
       "│    │    └─Conv1d: 3-17                 [10, 512, 8]              786,944\n",
       "│    │    └─BatchNorm1d: 3-18            [10, 512, 8]              1,024\n",
       "│    │    └─ReLU: 3-19                   [10, 512, 8]              --\n",
       "│    │    └─MaxPool1d: 3-20              [10, 512, 4]              --\n",
       "│    └─Conv_block: 2-6                   [10, 512, 2]              --\n",
       "│    │    └─Conv1d: 3-21                 [10, 512, 4]              786,944\n",
       "│    │    └─BatchNorm1d: 3-22            [10, 512, 4]              1,024\n",
       "│    │    └─ReLU: 3-23                   [10, 512, 4]              --\n",
       "│    │    └─MaxPool1d: 3-24              [10, 512, 2]              --\n",
       "│    └─Linear: 2-7                       [10, 48]                  49,200\n",
       "│    └─Linear: 2-8                       [10, 1]                   49\n",
       "│    └─Linear: 2-9                       [10, 1]                   1,025\n",
       "├─Spice_Decoder: 1-2                     [10, 32, 6]               --\n",
       "│    └─Linear: 2-10                      [10, 1, 48]               96\n",
       "│    └─Linear: 2-11                      [10, 1, 1024]             50,176\n",
       "│    └─Deconv_block: 2-12                [10, 256, 4]              512\n",
       "│    │    └─MaxUnpool1d: 3-25            [10, 512, 4]              --\n",
       "│    │    └─ConvTranspose1d: 3-26        [10, 256, 4]              393,472\n",
       "│    │    └─ReLU: 3-27                   [10, 256, 4]              --\n",
       "│    └─Deconv_block: 2-13                [10, 256, 6]              512\n",
       "│    │    └─MaxUnpool1d: 3-28            [10, 256, 6]              --\n",
       "│    │    └─ConvTranspose1d: 3-29        [10, 256, 6]              196,864\n",
       "│    │    └─ReLU: 3-30                   [10, 256, 6]              --\n",
       "│    └─Deconv_block: 2-14                [10, 256, 6]              512\n",
       "│    │    └─ConvTranspose1d: 3-31        [10, 256, 6]              196,864\n",
       "│    │    └─ReLU: 3-32                   [10, 256, 6]              --\n",
       "│    └─Deconv_block: 2-15                [10, 128, 6]              256\n",
       "│    │    └─ConvTranspose1d: 3-33        [10, 128, 6]              98,432\n",
       "│    │    └─ReLU: 3-34                   [10, 128, 6]              --\n",
       "│    └─Deconv_block: 2-16                [10, 64, 6]               128\n",
       "│    │    └─ConvTranspose1d: 3-35        [10, 64, 6]               24,640\n",
       "│    │    └─ReLU: 3-36                   [10, 64, 6]               --\n",
       "│    └─Deconv_block: 2-17                [10, 32, 6]               64\n",
       "│    │    └─ConvTranspose1d: 3-37        [10, 32, 6]               6,176\n",
       "│    │    └─ReLU: 3-38                   [10, 32, 6]               --\n",
       "==========================================================================================\n",
       "Total params: 3,114,082\n",
       "Trainable params: 3,114,082\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 253.27\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 6.75\n",
       "Params size (MB): 12.45\n",
       "Estimated Total Size (MB): 19.20\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(s, input_size=[10, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(0,5,1).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = torch.arange(10, 40, 1, dtype=torch.float64).reshape((10,3))\n",
    "x_2 = torch.arange(50, 80, 1, dtype=torch.float64).reshape((10,3))\n",
    "hat_x_1 = torch.arange(0, 30, 1, dtype=torch.float64).reshape((10,3))\n",
    "hat_x_2 = torch.arange(0, 30, 1, dtype=torch.float64).reshape((10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = t.mean(t.add(t.square(t.linalg.norm(t.sub(x_1, hat_x_1), dim=1, ord=2)),\n",
    "                        t.square(t.linalg.norm(t.sub(x_2, hat_x_2), dim=1, ord=2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foww(x,):\n",
    "    c1 = nn.Conv1d(1, 64, kernel_size=3, padding=1, stride=1 ,bias=True)  # same padding ,\n",
    "    mx = nn.MaxPool1d(kernel_size=3, stride=2, padding=1, return_indices=True )  # valid padding, stride=kernel_size\n",
    "    x = c1(x)\n",
    "    print('Layer 1: ', x.size())\n",
    "    x, i1 = mx(x)\n",
    "    print('Layer 1 after Pooling: ', x.size())\n",
    "    print(\"batchsize: \", x.size()[0])\n",
    "    \n",
    "    c2 = nn.Conv1d(64, 128, kernel_size=3, padding=1, stride=1 ,bias=True) \n",
    "    x = c2(x)\n",
    "    print('Layer 2: ', x.size())\n",
    "    x, i2 = mx(x)\n",
    "    print('Layer 2 after Pooling: ', x.size())\n",
    "\n",
    "\n",
    "    c3 = nn.Conv1d(128, 256, kernel_size=3, padding=1, stride=1 ,bias=True)\n",
    "    x = c3(x)\n",
    "    print('Layer 3: ', x.size())\n",
    "    x, i3 = mx(x)\n",
    "    print('Layer 3 after Pooling: ', x.size())\n",
    "    return x, [i1, i2 ,i3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = foww(torch.arange(0, 1280, 1).type(torch.FloatTensor).reshape(10, 1, -1))\n",
    "print(\"output\", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(0, 12, 1).type(torch.FloatTensor).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 1024, 1).type(torch.FloatTensor)\n",
    "k = torch.tensor([1, 2, -1]).type(torch.FloatTensor)\n",
    "l = torch.arange(0, 512, 1).type(torch.FloatTensor)\n",
    "BATCH_SIZE, IN_CH, OUT_CH = 1, 1, 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = nn.MaxPool1d(kernel_size=2, stride=1, padding=0 ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad with len(k)-1 zeros to ensure all non-zero outputs are computed.\n",
    "h = nn.Conv1d(IN_CH, OUT_CH, kernel_size=512, padding=1, stride=4 ,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad with len(k)-1 zeros to ensure all non-zero outputs are computed.\n",
    "d = nn.Conv2d(IN_CH, OUT_CH, kernel_size=512, padding=511, stride=4 , bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reshape(BATCH_SIZE, IN_CH, -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =d(x.reshape(BATCH_SIZE, IN_CH, -1))\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx(y).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fed21d7f443e9082cfc6ba2fbe018596127843c8658e141820a67f60820f8cf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.11 ('mpa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
