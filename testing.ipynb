{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 13:36:34.200920: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-23 13:36:34.420058: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-23 13:36:35.164033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from utils.model import Spice_model\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "from data_files.dataloader import MedleyDBLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.model import Spice_model\n",
    "from utils.training_script import Trainer\n",
    "from optims.loss import Huber_loss, Recons_loss, Conf_loss\n",
    "from data_files.dataset import CQT_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16000\n",
    "med = MedleyDBLoader(fs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9528461205301544e+16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = 1110.0644999999954 \n",
    "f2 = -5.684341886080802e-14\n",
    "dive = f1/f2\n",
    "dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23855/3868652844.py:1: RuntimeWarning: invalid value encountered in log2\n",
      "  np.log2(dive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(dive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.read_pickle('./CQT_data/MIR1k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnp = np.load('./CQT_data/MedleyDB.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnp = torch.toTe(nnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3530, 191)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (2824, 191)\n",
      "train_batch NUmber:  45\n",
      "diff batch shape: torch.Size([64])\n",
      "slice1 batch shape: torch.Size([64, 128])\n",
      "slice2 batch shape: torch.Size([64])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([64])\n",
      "torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 32, 4])\n",
      "batch shape: torch.Size([8])\n",
      "torch.Size([8, 1]) torch.Size([8, 1]) torch.Size([8, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "#data_pd = pd.DataFrame(data=nnp) \n",
    "train, val = train_test_split(data_pd, train_size=0.8, test_size=0.2, random_state=1)\n",
    "print(\"train shape: \", train.shape)\n",
    "train_batches = DataLoader(CQT_Dataset(data=train, mode='train'), batch_size=64, shuffle=True)\n",
    "print(\"train_batch NUmber: \", len(train_batches))\n",
    "diff, slice1, slice2, f0 = next(iter(train_batches))\n",
    "print(f\"diff batch shape: {diff.size()}\")\n",
    "print(f\"slice1 batch shape: {slice1.size()}\")\n",
    "print(f\"slice2 batch shape: {f0.size()}\")\n",
    "\n",
    "spice = Spice_model()\n",
    "\n",
    "\n",
    "for b in train_batches:\n",
    "    print(\"batch shape:\", b[0].shape)\n",
    "    pitch_diff, x_1, x_2, f0 = b\n",
    "    x_1 = x_1.type(torch.FloatTensor)\n",
    "    #print(x_1.shape, x_1.type())\n",
    "    a, x, y = spice(x_1)\n",
    "    print(a.size(), x.size(), y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=torch.arange(0, 25, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = xx.reshape((5,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./CQT_data/MIR1k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,25,1).reshape(5,5)[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0,15,1).reshape(5,3)\n",
    "a = np.hstack((a, np.array([0.25,0.7,0,0.5,0]).reshape(-1,1)))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows of cqt where label (last) column is zero\n",
    "df.drop(df.loc[df.iloc[:, -1]==0].index, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder forward torch.FloatTensor\n",
      "Encoder forward torch.FloatTensor\n",
      "Encoder forward torch.FloatTensor\n",
      "Encoder forward torch.FloatTensor\n",
      "Encoder forward torch.FloatTensor\n",
      "Encoder forward torch.FloatTensor\n",
      "no unpooling True True\n",
      "no unpooling False True\n",
      "no unpooling False True\n",
      "no unpooling False True\n",
      "no unpooling False True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Spice_model                              [10, 1]                   --\n",
       "├─Spice_Encoder: 1-1                     [10, 1]                   --\n",
       "│    └─Conv_block: 2-1                   [10, 64, 64]              --\n",
       "│    │    └─Conv1d: 3-1                  [10, 64, 128]             256\n",
       "│    │    └─BatchNorm1d: 3-2             [10, 64, 128]             128\n",
       "│    │    └─ReLU: 3-3                    [10, 64, 128]             --\n",
       "│    │    └─MaxPool1d: 3-4               [10, 64, 64]              --\n",
       "│    └─Conv_block: 2-2                   [10, 128, 32]             --\n",
       "│    │    └─Conv1d: 3-5                  [10, 128, 64]             24,704\n",
       "│    │    └─BatchNorm1d: 3-6             [10, 128, 64]             256\n",
       "│    │    └─ReLU: 3-7                    [10, 128, 64]             --\n",
       "│    │    └─MaxPool1d: 3-8               [10, 128, 32]             --\n",
       "│    └─Conv_block: 2-3                   [10, 256, 16]             --\n",
       "│    │    └─Conv1d: 3-9                  [10, 256, 32]             98,560\n",
       "│    │    └─BatchNorm1d: 3-10            [10, 256, 32]             512\n",
       "│    │    └─ReLU: 3-11                   [10, 256, 32]             --\n",
       "│    │    └─MaxPool1d: 3-12              [10, 256, 16]             --\n",
       "│    └─Conv_block: 2-4                   [10, 512, 8]              --\n",
       "│    │    └─Conv1d: 3-13                 [10, 512, 16]             393,728\n",
       "│    │    └─BatchNorm1d: 3-14            [10, 512, 16]             1,024\n",
       "│    │    └─ReLU: 3-15                   [10, 512, 16]             --\n",
       "│    │    └─MaxPool1d: 3-16              [10, 512, 8]              --\n",
       "│    └─Conv_block: 2-5                   [10, 512, 4]              --\n",
       "│    │    └─Conv1d: 3-17                 [10, 512, 8]              786,944\n",
       "│    │    └─BatchNorm1d: 3-18            [10, 512, 8]              1,024\n",
       "│    │    └─ReLU: 3-19                   [10, 512, 8]              --\n",
       "│    │    └─MaxPool1d: 3-20              [10, 512, 4]              --\n",
       "│    └─Conv_block: 2-6                   [10, 512, 2]              --\n",
       "│    │    └─Conv1d: 3-21                 [10, 512, 4]              786,944\n",
       "│    │    └─BatchNorm1d: 3-22            [10, 512, 4]              1,024\n",
       "│    │    └─ReLU: 3-23                   [10, 512, 4]              --\n",
       "│    │    └─MaxPool1d: 3-24              [10, 512, 2]              --\n",
       "│    └─Linear: 2-7                       [10, 48]                  49,200\n",
       "│    └─Linear: 2-8                       [10, 1]                   49\n",
       "│    └─Linear: 2-9                       [10, 1]                   1,025\n",
       "├─Spice_Decoder: 1-2                     [10, 32, 4]               --\n",
       "│    └─Linear: 2-10                      [10, 1, 48]               96\n",
       "│    └─Linear: 2-11                      [10, 1, 1024]             50,176\n",
       "│    └─Deconv_block: 2-12                [10, 256, 4]              512\n",
       "│    │    └─MaxUnpool1d: 3-25            [10, 512, 4]              --\n",
       "│    │    └─ConvTranspose1d: 3-26        [10, 256, 4]              393,472\n",
       "│    │    └─ReLU: 3-27                   [10, 256, 4]              --\n",
       "│    └─Deconv_block: 2-13                [10, 256, 4]              512\n",
       "│    │    └─ConvTranspose1d: 3-28        [10, 256, 4]              196,864\n",
       "│    │    └─ReLU: 3-29                   [10, 256, 4]              --\n",
       "│    └─Deconv_block: 2-14                [10, 256, 4]              512\n",
       "│    │    └─ConvTranspose1d: 3-30        [10, 256, 4]              196,864\n",
       "│    │    └─ReLU: 3-31                   [10, 256, 4]              --\n",
       "│    └─Deconv_block: 2-15                [10, 128, 4]              256\n",
       "│    │    └─ConvTranspose1d: 3-32        [10, 128, 4]              98,432\n",
       "│    │    └─ReLU: 3-33                   [10, 128, 4]              --\n",
       "│    └─Deconv_block: 2-16                [10, 64, 4]               128\n",
       "│    │    └─ConvTranspose1d: 3-34        [10, 64, 4]               24,640\n",
       "│    │    └─ReLU: 3-35                   [10, 64, 4]               --\n",
       "│    └─Deconv_block: 2-17                [10, 32, 4]               64\n",
       "│    │    └─ConvTranspose1d: 3-36        [10, 32, 4]               6,176\n",
       "│    │    └─ReLU: 3-37                   [10, 32, 4]               --\n",
       "==========================================================================================\n",
       "Total params: 3,114,082\n",
       "Trainable params: 3,114,082\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 242.81\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 6.63\n",
       "Params size (MB): 12.45\n",
       "Estimated Total Size (MB): 19.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Spice_model()\n",
    "summary(s, input_size=[10, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n",
      "<class 'torch.nn.parameter.Parameter'> True\n"
     ]
    }
   ],
   "source": [
    "for n, param in s.named_parameters():\n",
    "    print(type(param), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fed21d7f443e9082cfc6ba2fbe018596127843c8658e141820a67f60820f8cf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.11 ('mpa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
